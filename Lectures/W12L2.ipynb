{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 12 Lecture 2 - Prior elicitation\n",
    "\n",
    "A key paper in this area from [Mikkola et al. 2024](https://projecteuclid.org/journals/bayesian-analysis/volume-19/issue-4/Prior-Knowledge-Elicitation-The-Past-Present-and-Future/10.1214/23-BA1381.full).\n",
    "\n",
    "And a great blog post from [Michael Bettancourt](https://betanalpha.github.io/assets/case_studies/prior_modeling.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy as sp \n",
    "import random as rd\n",
    "import pdb\n",
    "import pymc as pm\n",
    "import patsy\n",
    "import arviz as az\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "import dataframe_image as dfi\n",
    "import pytensor as pyt\n",
    "from scipy.optimize import minimize\n",
    "from math import factorial as f\n",
    "\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "def stdize(x):\n",
    "    return (x-np.mean(x))/np.std(x)\n",
    "\n",
    "\n",
    "def indexall(L):\n",
    "    poo = []\n",
    "    for p in L:\n",
    "        if not p in poo:\n",
    "            poo.append(p)\n",
    "    Ix = np.array([poo.index(p) for p in L])\n",
    "    return poo,Ix\n",
    "\n",
    "def indexall_(L):\n",
    "    Il, Ll = pd.factorize(L, sort=True)\n",
    "    return Ll, Il\n",
    "\n",
    "\n",
    "\n",
    "# Binomial distribution\n",
    "def dbinom(x,n,p):\n",
    "    return f(n)/(f(x)*f(n-x))*p**(x)*(1-p)**(n-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whence piors?\n",
    "\n",
    "A key question in Bayesian modelling lies in what are priors anyhow? What do they represent? The most succinct definition is that priors are representations of our personal beliefs. But how can we do that? It seems both sensible and nonsense at the same time\n",
    "\n",
    "> \"...statistics are always to some extent constructed on the basis of judgements, and it would be an obvious delusion to think the full complexity of personal experience can be unambiguously coded and put into a spreadsheet or other software.\" -- David Spiegelhalter\n",
    "\n",
    "And yet this is ultimately what Bayes theorem demands of us\n",
    "\n",
    "> \"In Bayesian theory, a 'prior' represents one's personal degree of belief before considering current evidence.\" -- ET Jaynes\n",
    "\n",
    "So if this is the case, and we wish to set priors in a principled way, how can we go about it? How should we go about specifying our own priors? And how can we specify the priors of others?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Priors\n",
    "\n",
    "As a first step, when we start to think about priors we need to first define the scale of what we're talking about. The first example often given on the topic - perhaps because bounds make things easier to think about - is of prior probabitily, how likely we think something is to happen, or what percentage something is. If we think back to our second lecture with the percentage of water on the earth, we can asign likelhood values to each percentage of water and get something we think is reasonable. \n",
    "\n",
    "For example, my personal beliefs about the percentage of water is that it is something near 72%, but certainly not less than 65% and certainly not more than 80%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subjective prior\n",
    "my_prior = np.array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
    "\n",
    "# Fill in relevant values\n",
    "my_prior[64:79] = np.array([1., 2., 3., 5., 7., 8., 9., 10., 9., 8., 6., 4., 3., 2., 1.])\n",
    "# Normalize\n",
    "my_prior = my_prior/sum(my_prior)\n",
    "my_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Beta distribution PDF\n",
    "plt.figure(figsize=(8, 6))\n",
    "x = np.linspace(0, 1, len(my_prior))\n",
    "plt.plot(x, my_prior, label=\"My prior\", color='blue')\n",
    "\n",
    "# Add graph details\n",
    "plt.title(\"My priors about water on earth\", fontsize=14)\n",
    "plt.xlabel(\"Probability\", fontsize=12)\n",
    "plt.ylabel(\"PDF Value\", fontsize=12)\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.axvline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.axvline(0.72, color='red', linewidth=0.8)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.4)\n",
    "plt.savefig('my_prior.jpg',dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then apply this to the data from class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grid\n",
    "p_grid = np.linspace(0,1,len(my_prior))\n",
    "p_grid\n",
    "\n",
    "# New observations\n",
    "W = 6\n",
    "L = 5\n",
    "# Number of trials\n",
    "N = W+L\n",
    "\n",
    "# Calculate likelihood\n",
    "likelihood = dbinom(W,N,p_grid)\n",
    "\n",
    "# Bayes theorem\n",
    "posterior = (likelihood*my_prior)/sum(likelihood*my_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot posterior over range of p_grid\n",
    "plt.plot(p_grid, posterior, label='Posterior')\n",
    "plt.plot(p_grid, likelihood/sum(likelihood), linestyle=\"-\", label='Likelihood')\n",
    "plt.plot(p_grid, my_prior, linestyle=\":\", label='Prior')\n",
    "plt.legend()\n",
    "plt.xlabel('Proportion water'),plt.ylabel('Posterior')\n",
    "plt.savefig('my_prior_anal.jpg',dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might seem a little ad-hoc to you; is there something more formal we can do? The canonical reference for elicitaiton is [*Uncertain Judgements*](https://onlinelibrary.wiley.com/doi/book/10.1002/0470033312) by O'Hagan *et al*. (2006), who point out that with only a few datapoints we can parameterize a distribution using the cumulative distribution function for an appropriate distribution. \n",
    "\n",
    "Using my numbers above and interpreting 'certainly' as P>0.001 and P<0.999, we can find the closest cdf from a Beta distribution that represents probabilities:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target values for the CDF\n",
    "target_cdf_values = [0.5, 0.001, 0.999]\n",
    "target_probs = [0.72, 0.65, 0.80]\n",
    "\n",
    "# Define the objective function to minimize the difference between target and actual CDF values\n",
    "def objective(params):\n",
    "    alpha, beta = params\n",
    "    cdf_values = [sp.stats.beta.cdf(p, alpha, beta) for p in target_probs]\n",
    "    return np.sum((np.array(cdf_values) - np.array(target_cdf_values))**2)\n",
    "\n",
    "# Initial guess for alpha and beta\n",
    "initial_guess = [2, 2]\n",
    "\n",
    "# Bounds for alpha and beta\n",
    "bounds = [(1e-6, None), (1e-6, None)]\n",
    "\n",
    "# Minimize the objective function\n",
    "result = minimize(objective, initial_guess, bounds=bounds)\n",
    "\n",
    "# Extract optimal alpha and beta\n",
    "optimal_alpha, optimal_beta = result.x\n",
    "\n",
    "# Compute CDF values with the fitted parameters\n",
    "fitted_cdf_values = [sp.stats.beta.cdf(p, optimal_alpha, optimal_beta) for p in target_probs]\n",
    "\n",
    "optimal_alpha, optimal_beta, fitted_cdf_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can take a look at how we've done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate points for the Beta distribution CDF\n",
    "x = np.linspace(0, 1, len(my_prior))\n",
    "y = sp.stats.beta.cdf(x, optimal_alpha, optimal_beta)\n",
    "\n",
    "# Plot the Beta distribution CDF\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x, y, label=\"Beta CDF (α=282.47, β=110.06)\", color='blue')\n",
    "\n",
    "# Add target points\n",
    "plt.scatter(target_probs, target_cdf_values, color='red', label=\"Target Points\", zorder=5)\n",
    "\n",
    "# Add labels for the target points\n",
    "for prob, cdf in zip(target_probs, target_cdf_values):\n",
    "    plt.text(prob, cdf, f\"({prob}, {cdf})\", fontsize=9, ha='left', va='bottom')\n",
    "\n",
    "# Add graph details\n",
    "plt.title(\"Fitted Beta Distribution CDF\", fontsize=14)\n",
    "plt.xlabel(\"Probability\", fontsize=12)\n",
    "plt.ylabel(\"CDF Value\", fontsize=12)\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.axvline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.4)\n",
    "plt.savefig('binom_elicit_beta_cdf.jpg',dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a prior to work with that seems a bit more grounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate points for the Beta distribution PDF\n",
    "pdf_y = sp.stats.beta.pdf(x, optimal_alpha, optimal_beta)\n",
    "\n",
    "# Plot the Beta distribution PDF\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x, pdf_y, label=\"Beta PDF (α=282.47, β=110.06)\", color='green')\n",
    "\n",
    "# Add graph details\n",
    "plt.title(\"Fitted Beta Distribution PDF\", fontsize=14)\n",
    "plt.xlabel(\"Probability\", fontsize=12)\n",
    "plt.ylabel(\"PDF Value\", fontsize=12)\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.axvline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.4)\n",
    "plt.savefig('binom_elicit_beta_pdf_prior.jpg',dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run this through Bayes theorem on the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayes theorem\n",
    "posterior2 = (likelihood*pdf_y)/sum(likelihood*pdf_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot posterior over range of p_grid\n",
    "plt.plot(p_grid, posterior, label='Posterior')\n",
    "plt.plot(p_grid, likelihood/sum(likelihood), linestyle=\"-\", label='Likelihood')\n",
    "plt.plot(p_grid, my_prior, linestyle=\":\", label='Prior')\n",
    "plt.plot(p_grid, pdf_y/sum(pdf_y), linestyle=\":\", label='Elicit Prior')\n",
    "plt.plot(p_grid, posterior2, label='Elict Posterior')\n",
    "plt.legend()\n",
    "plt.xlabel('Proportion water'),plt.ylabel('Posterior')\n",
    "plt.savefig('my_prior_anal2.jpg',dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple respondents\n",
    "\n",
    "Now in practice we might want to do better than a single person's guess as to the distribution of water; instead we may poll a group of experts on the question at hand. Assuming we have 5 people interviewed, we can undertake the same exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated target values\n",
    "target_cdf_values_multi = [0.5, 0.001, 0.999]\n",
    "target_prob_ranges = np.array([\n",
    "    [0.72, 0.68, 0.70],  # Around 0.5\n",
    "    [0.65, 0.62, 0.69],  # Around 0.001\n",
    "    [0.80, 0.82, 0.75],  # Around 0.999\n",
    "]).T\n",
    "\n",
    "# Define a modified objective function for multiple target points\n",
    "def objective_multi(params):\n",
    "    alpha, beta = params\n",
    "    total_error = 0\n",
    "    for target_probs, target_cdf in zip(target_prob_ranges, target_cdf_values_multi):\n",
    "        cdf_values = [sp.stats.beta.cdf(p, alpha, beta) for p in target_probs]\n",
    "        avg_cdf = np.mean(cdf_values)\n",
    "        total_error += (avg_cdf - target_cdf)**2\n",
    "    return total_error\n",
    "\n",
    "# Minimize the objective function\n",
    "result_multi = minimize(objective_multi, initial_guess, bounds=bounds)\n",
    "\n",
    "# Extract optimal alpha and beta\n",
    "optimal_alpha_multi, optimal_beta_multi = result_multi.x\n",
    "\n",
    "# Compute CDF values for each set of points with the fitted parameters\n",
    "fitted_cdf_values_multi = [\n",
    "    [sp.stats.beta.cdf(p, optimal_alpha_multi, optimal_beta_multi) for p in target_probs]\n",
    "    for target_probs in target_prob_ranges\n",
    "]\n",
    "\n",
    "optimal_alpha_multi, optimal_beta_multi, fitted_cdf_values_multi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Beta distribution CDF with adjusted labels\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x, y_multi, label=f\"Beta CDF (α={optimal_alpha_multi:.2f}, β={optimal_beta_multi:.2f})\", color='blue')\n",
    "\n",
    "# Add target points and adjusted labels\n",
    "offsets = [0.02, 0.04, -0.03]  # Y-offsets for the text labels\n",
    "colors = ['red', 'green', 'purple']\n",
    "for i, (target_probs, target_cdf) in enumerate(zip(target_prob_ranges, target_cdf_values_multi)):\n",
    "    plt.scatter(target_probs, [target_cdf] * len(target_probs), color=colors[i], label=f\"Target Set {i+1}\", zorder=5)\n",
    "    for j, prob in enumerate(target_probs):\n",
    "        plt.text(prob, target_cdf + offsets[j % len(offsets)], f\"({prob:.2f}, {target_cdf})\", \n",
    "                 fontsize=8, ha='center', va='bottom', color=colors[i])\n",
    "\n",
    "# Add graph details\n",
    "plt.title(\"Fitted Beta Distribution CDF for Multiple Point Sets\", fontsize=14)\n",
    "plt.xlabel(\"Probability\", fontsize=12)\n",
    "plt.ylabel(\"CDF Value\", fontsize=12)\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.axvline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.4)\n",
    "plt.savefig('binom_elicit_beta_cdf_allone.jpg',dpi=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate points for the Beta distribution PDF\n",
    "pdf_y = sp.stats.beta.pdf(x, optimal_alpha_multi, optimal_beta_multi)\n",
    "\n",
    "# Plot the Beta distribution PDF\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x, pdf_y, label=\"Beta PDF (α=282.47, β=110.06)\", color='green')\n",
    "\n",
    "# Add graph details\n",
    "plt.title(\"Fitted Beta Distribution PDF\", fontsize=14)\n",
    "plt.xlabel(\"Probability\", fontsize=12)\n",
    "plt.ylabel(\"PDF Value\", fontsize=12)\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.axvline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.axvline(0.708, color='red', linewidth=0.8, linestyle='--')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.4)\n",
    "plt.savefig('binom_elicit_beta_pdf2.jpg',dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a prior - but heck it's really spiky! Really it's **too** informative about the quantity we're tyring to elicit. If the true percentage of water is 70.8% (vertical red line above), then we're saying *a priori*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats.beta.cdf(0.708, optimal_alpha_multi, optimal_beta_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a 0.0000000000001% chance of there being less than the true percentage of water on the earth, which seems like we're missing the boat. In truth we are - the optimizaiton is fitting 3 sets of 3 points with a function that doesn't account for the scale of each person's beliefs. We're throwing out individual uncertainty and optimizing the group mean uncertainty. So what can we do? \n",
    "\n",
    "One solution is to fit each set of estimates individually, then combine the resulting pdfs into a single esimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sets of target probabilities and corresponding CDF values for three curves\n",
    "target_cdf_values_list = [\n",
    "    [0.5, 0.001, 0.999],  # Target CDF values for the first curve\n",
    "    [0.5, 0.001, 0.999],  # Target CDF values for the second curve\n",
    "    [0.5, 0.001, 0.999],  # Target CDF values for the third curve\n",
    "]\n",
    "\n",
    "target_probs_list = [\n",
    "    [0.72, 0.65, 0.80],  # Target probabilities for the first curve\n",
    "    [0.68, 0.62, 0.82],  # Target probabilities for the second curve\n",
    "    [0.70, 0.69, 0.75],  # Target probabilities for the third curve\n",
    "]\n",
    "\n",
    "# Function to fit a Beta distribution for each set of points\n",
    "def fit_beta(target_probs, target_cdf_values):\n",
    "    def objective(params):\n",
    "        alpha, beta = params\n",
    "        cdf_values = [sp.stats.beta.cdf(p, alpha, beta) for p in target_probs]\n",
    "        return np.sum((np.array(cdf_values) - np.array(target_cdf_values))**2)\n",
    "\n",
    "    result = minimize(objective, initial_guess, bounds=bounds)\n",
    "    return result.x  # Return alpha and beta\n",
    "\n",
    "# Fit separate Beta distributions for each set of points\n",
    "fitted_params_list = [\n",
    "    fit_beta(target_probs, target_cdf_values)\n",
    "    for target_probs, target_cdf_values in zip(target_probs_list, target_cdf_values_list)\n",
    "]\n",
    "\n",
    "fitted_params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = p_grid\n",
    "# Extract individual parameters\n",
    "alpha_values, beta_values = zip(*fitted_params_list)\n",
    "\n",
    "# Plot CDFs for all three fitted distributions\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, (alpha, beta) in enumerate(zip(alpha_values, beta_values)):\n",
    "    y_cdf = sp.stats.beta.cdf(x, alpha, beta)\n",
    "    plt.plot(x, y_cdf, label=f\"Set {i+1} CDF (α={alpha:.2f}, β={beta:.2f})\")\n",
    "\n",
    "# Add graph details\n",
    "plt.title(\"Fitted Beta Distribution CDFs\", fontsize=14)\n",
    "plt.xlabel(\"Probability\", fontsize=12)\n",
    "plt.ylabel(\"CDF Value\", fontsize=12)\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.axvline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.4)\n",
    "plt.savefig('binom_elicit_beta_cdf_multi.jpg',dpi=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and plot PDFs for each set\n",
    "plt.figure(figsize=(10, 8))\n",
    "x = np.linspace(0, 1, 1000)\n",
    "\n",
    "for i, (params, target_probs) in enumerate(zip(fitted_params_list, target_probs_list)):\n",
    "    alpha, beta = params\n",
    "    y = sp.stats.beta.pdf(x, alpha, beta)\n",
    "    plt.plot(x, y, label=f\"Beta PDF {i+1} (α={alpha:.2f}, β={beta:.2f})\", lw=2)\n",
    "\n",
    "# Combine the three PDFs by taking a weighted average\n",
    "# Assume equal weighting for simplicity\n",
    "weights = [1/3, 1/3, 1/3]  # Equal weights for the three PDFs\n",
    "combined_pdf = sum(\n",
    "    weight * sp.stats.beta.pdf(x, alpha, beta)\n",
    "    for weight, (alpha, beta) in zip(weights, fitted_params_list)\n",
    ")\n",
    "\n",
    "# Function to estimate alpha and beta for the combined PDF\n",
    "def estimate_combined_alpha_beta(pdf, x):\n",
    "    def objective(params):\n",
    "        alpha, beta = params\n",
    "        estimated_pdf = sp.stats.beta.pdf(x, alpha, beta)\n",
    "        return np.sum((pdf - estimated_pdf) ** 2)\n",
    "\n",
    "    # Minimize the objective function to find the best alpha and beta\n",
    "    result = minimize(objective, initial_guess, bounds=bounds)\n",
    "    return result.x\n",
    "\n",
    "# Estimate alpha and beta for the combined PDF\n",
    "combined_alpha, combined_beta = estimate_combined_alpha_beta(combined_pdf, x)\n",
    "\n",
    "plt.plot(x, sp.stats.beta.pdf(x,combined_alpha, combined_beta), label=f\"Combined PDF {i+1} (α={combined_alpha:.2f}, β={combined_beta:.2f})\", color=\"purple\", lw=2)\n",
    "\n",
    "# Add graph details\n",
    "plt.title(\"Fitted Beta Distribution PDFs for Separate CDF Curves\", fontsize=14)\n",
    "plt.xlabel(\"Probability\", fontsize=12)\n",
    "plt.ylabel(\"PDF Value\", fontsize=12)\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.axvline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.4)\n",
    "plt.savefig('binom_elicit_beta_pdf3.jpg',dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the weights are equal - we assume equal expertise for all individuals. But what if we value some opinions over others? There are many possible methods to figure out weightings:\n",
    "\n",
    "\n",
    "1. Performance-Based Weighting\n",
    "\n",
    "    Assign weights based on the historical accuracy of each expert in similar contexts or test scenarios.\n",
    "    Implementation:\n",
    "        Test experts on questions with known answers.\n",
    "        Calculate weights proportional to the inverse of their error rates (e.g., Brier score for probabilistic predictions).\n",
    "        Normalize weights to sum to 1.\n",
    "\n",
    "2. Self-Assessment\n",
    "\n",
    "    Let experts rate their confidence or expertise.\n",
    "    Implementation:\n",
    "        Collect confidence scores from experts.\n",
    "        Normalize these scores to sum to 1.\n",
    "    Limitations: May introduce bias as experts might over- or underestimate their abilities.\n",
    "\n",
    "3. Calibration and Informativeness Scoring\n",
    "\n",
    "    Evaluate experts based on their calibration (how well probabilities match observed frequencies) and informativeness (the specificity of their predictions).\n",
    "    Implementation:\n",
    "        Compute calibration scores (e.g., using a reliability diagram).\n",
    "        Combine with informativeness measures (e.g., entropy reduction or Kullback-Leibler divergence).\n",
    "        Assign higher weights to well-calibrated and informative experts.\n",
    "\n",
    "4. Behavioral Aggregation\n",
    "\n",
    "    Use elicitation techniques to gather meta-judgments about the reliability of peers.\n",
    "    Implementation:\n",
    "        Ask experts to assess the relative reliability of others.\n",
    "        Use these assessments to construct a weighting scheme (e.g., using pairwise comparisons or ranking).\n",
    "\n",
    "5. Bayesian Methods\n",
    "\n",
    "    Treat expert weights as parameters in a Bayesian model and update them based on data or performance.\n",
    "    Implementation:\n",
    "        Use a prior distribution for weights.\n",
    "        Update weights based on observed data (e.g., accuracy of predictions or outcomes of test scenarios).\n",
    "\n",
    "6. Delphi Method\n",
    "\n",
    "    Iteratively refine expert judgments through structured feedback and convergence.\n",
    "    Implementation:\n",
    "        Conduct multiple rounds of elicitation.\n",
    "        Weigh experts more heavily if their opinions stabilize around a consensus.\n",
    "\n",
    "7. Equal Weighting\n",
    "\n",
    "    Assign equal weights when there is no clear basis for differential weighting.\n",
    "    Use Case: Appropriate when there is no performance data or clear distinction in expertise.\n",
    "\n",
    "Assuming we perform one of these, we can re-weight the Beta parameters for each model accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and plot PDFs for each set\n",
    "plt.figure(figsize=(10, 8))\n",
    "x = np.linspace(0, 1, 1000)\n",
    "\n",
    "for i, (params, target_probs) in enumerate(zip(fitted_params_list, target_probs_list)):\n",
    "    alpha, beta = params\n",
    "    y = sp.stats.beta.pdf(x, alpha, beta)\n",
    "    plt.plot(x, y, label=f\"Beta PDF {i+1} (α={alpha:.2f}, β={beta:.2f})\", lw=2)\n",
    "\n",
    "# Combine the three PDFs by taking a weighted average\n",
    "# Assume equal weighting for simplicity\n",
    "weights = [.2, .7, .1]  # Equal weights for the three PDFs\n",
    "combined_pdf = sum(\n",
    "    weight * sp.stats.beta.pdf(x, alpha, beta)\n",
    "    for weight, (alpha, beta) in zip(weights, fitted_params_list)\n",
    ")\n",
    "\n",
    "# Function to estimate alpha and beta for the combined PDF\n",
    "def estimate_combined_alpha_beta(pdf, x):\n",
    "    def objective(params):\n",
    "        alpha, beta = params\n",
    "        estimated_pdf = sp.stats.beta.pdf(x, alpha, beta)\n",
    "        return np.sum((pdf - estimated_pdf) ** 2)\n",
    "\n",
    "    # Minimize the objective function to find the best alpha and beta\n",
    "    result = minimize(objective, initial_guess, bounds=bounds)\n",
    "    return result.x\n",
    "\n",
    "# Estimate alpha and beta for the combined PDF\n",
    "combined_alpha, combined_beta = estimate_combined_alpha_beta(combined_pdf, x)\n",
    "\n",
    "plt.plot(x, sp.stats.beta.pdf(x,combined_alpha, combined_beta), label=f\"Combined PDF {i+1} (α={combined_alpha:.2f}, β={combined_beta:.2f})\", color=\"purple\", lw=2)\n",
    "\n",
    "# Add graph details\n",
    "plt.title(\"Fitted Beta Distribution PDFs for Separate CDF Curves\", fontsize=14)\n",
    "plt.xlabel(\"Probability\", fontsize=12)\n",
    "plt.ylabel(\"PDF Value\", fontsize=12)\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.axvline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.4)\n",
    "plt.savefig('binom_elicit_beta_pdf4.jpg',dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This elicitation is on the probability scale, but what if we're dealing with logOdds? How can we convert to the real line? Well we can convert to a Normal distribution by getting the joint Beta mean and variance\n",
    "\n",
    "$$\n",
    "\\mu_{Beta} = \\frac{\\alpha}{\\alpha+\\beta}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma^2_{Beta} = \\frac{\\alpha \\beta} {(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}\n",
    "$$\n",
    "\n",
    "which we can then transform to the log-odds scale\n",
    "\n",
    "$$\n",
    "\\mu = logit(\\mu_{Beta})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma = \\sqrt[2][\\frac{\\sigma^2_{Beta}}{\\mu_{Beta}(1-\\mu_{Beta})^2}]\n",
    "$$\n",
    "\n",
    "and plug into a normal distribtion\n",
    "\n",
    "$$\n",
    "\\sim N(\\mu, \\sigma)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the logit function and its inverse\n",
    "def logit(p):\n",
    "    return np.log(p / (1 - p))\n",
    "\n",
    "def invlogit(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Compute the mean and variance of the Beta distribution\n",
    "mean_beta = combined_alpha / (combined_alpha + combined_beta)\n",
    "var_beta = (combined_alpha * combined_beta) / ((combined_alpha + combined_beta) ** 2 * (combined_alpha + combined_beta + 1))\n",
    "\n",
    "# Find the parameters for the Normal distribution that closely matches\n",
    "# the transformed Beta distribution under the logit link\n",
    "mean_normal = logit(mean_beta)\n",
    "sd_normal = np.sqrt((var_beta / (mean_beta * (1 - mean_beta)) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and plot PDFs for each set\n",
    "plt.figure(figsize=(10, 8))\n",
    "x = np.linspace(0, 1, 1000)\n",
    "\n",
    "for i, (params, target_probs) in enumerate(zip(fitted_params_list, target_probs_list)):\n",
    "    alpha, beta = params\n",
    "    y = sp.stats.beta.pdf(x, alpha, beta)\n",
    "    plt.plot(x, y, label=f\"Beta PDF {i+1} (α={alpha:.2f}, β={beta:.2f})\", lw=2)\n",
    "\n",
    "# Combine the three PDFs by taking a weighted average\n",
    "# Assume equal weighting for simplicity\n",
    "weights = [1/3, 1/3, 1/3]  # Equal weights for the three PDFs\n",
    "combined_pdf = sum(\n",
    "    weight * sp.stats.beta.pdf(x, alpha, beta)\n",
    "    for weight, (alpha, beta) in zip(weights, fitted_params_list)\n",
    ")\n",
    "\n",
    "# Function to estimate alpha and beta for the combined PDF\n",
    "def estimate_combined_alpha_beta(pdf, x):\n",
    "    def objective(params):\n",
    "        alpha, beta = params\n",
    "        estimated_pdf = sp.stats.beta.pdf(x, alpha, beta)\n",
    "        return np.sum((pdf - estimated_pdf) ** 2)\n",
    "\n",
    "    # Minimize the objective function to find the best alpha and beta\n",
    "    result = minimize(objective, initial_guess, bounds=bounds)\n",
    "    return result.x\n",
    "\n",
    "# Estimate alpha and beta for the combined PDF\n",
    "combined_alpha, combined_beta = estimate_combined_alpha_beta(combined_pdf, x)\n",
    "\n",
    "plt.plot(x, sp.stats.beta.pdf(x,combined_alpha, combined_beta), label=f\"Combined PDF (α={combined_alpha:.2f}, β={combined_beta:.2f})\", color=\"purple\", lw=2)\n",
    "\n",
    "x2 = np.linspace(-5, 5, 1000)\n",
    "y2 = sp.stats.norm.pdf(x2, mean_normal, sd_normal)\n",
    "plt.plot(invlogit(x2), (y2/max(y2))*max(sp.stats.beta.pdf(x,combined_alpha, combined_beta)), label=f\"Normal-logit PDF (μ={mean_normal:.2f}, σ={sd_normal:.2f})\", color=\"black\", lw=2, linestyle=':')\n",
    "\n",
    "\n",
    "# Add graph details\n",
    "plt.title(\"Fitted Beta Distribution PDFs for Separate CDF Curves and combined\", fontsize=14)\n",
    "plt.xlabel(\"Probability\", fontsize=12)\n",
    "plt.ylabel(\"PDF Value\", fontsize=12)\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.axvline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.legend()\n",
    "plt.xlim(0.6, 0.82)\n",
    "plt.grid(alpha=0.4)\n",
    "\n",
    "plt.savefig('logOdds_beta.jpg',dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beside eliciting bounds or ranges of things, there are many other ways of getting at the underlying (implied) paramers of a probability distribution. One highlighted by O'Hagan *et al.* is the *equivalent prior sample* (EST) method, which recognizes that elicition methods often make the uncertainties too low, even for an opinion from one person. \n",
    "\n",
    "The EST method asks for a point estimate of the expected value (in my case, 0.72) but also then asks \"based on how many samples?\" Then given $n$ the calculation can be made that $\\alpha = n\\hat{p}$ and $\\beta = n(1-\\hat{p})$.\n",
    "\n",
    "For examples about the earth, there is only one, so the resulting pdf would simply be $Beta(0.72, 0.18)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate points for the Beta distribution PDF\n",
    "pdf_y = sp.stats.beta.pdf(x, 0.72, 0.18)\n",
    "\n",
    "# Plot the Beta distribution PDF\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x, pdf_y, label=\"Beta PDF (α=0.72, β=0.18)\", color='green')\n",
    "\n",
    "# Add graph details\n",
    "plt.title(\"Some Beta Distribution PDF\", fontsize=14)\n",
    "plt.xlabel(\"Probability\", fontsize=12)\n",
    "plt.ylabel(\"PDF Value\", fontsize=12)\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.axvline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.4)\n",
    "plt.savefig('one_earth.jpg',dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is a bit of a crap estimate. But let's instead use samples from people to give some perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate points for the Beta distribution PDF\n",
    "\n",
    "# Plot the Beta distribution PDF\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x, sp.stats.beta.pdf(x, 5*0.72, 0.18), label=\"Beta PDF (α=0.72, β=0.18)\")\n",
    "plt.plot(x, sp.stats.beta.pdf(x, 5*0.72, 5*0.18), label=\"Beta PDF  (α=5x0.72, β=5x0.18)\")\n",
    "plt.plot(x, sp.stats.beta.pdf(x, 10*0.72, 10*0.18), label=\"Beta PDF  (α=10x0.72, β=10x0.18)\")\n",
    "plt.plot(x, sp.stats.beta.pdf(x, 50*0.72, 50*0.18), label=\"Beta PDF  (α=50x0.72, β=50x0.18)\")\n",
    "plt.plot(x, sp.stats.beta.pdf(x, 500*0.72, 500*0.18), label=\"Beta PDF  (α=500x0.72, β=500x0.18)\")\n",
    "\n",
    "\n",
    "# Add graph details\n",
    "plt.title(\"Some Beta Distributions PDF\", fontsize=14)\n",
    "plt.xlabel(\"Probability\", fontsize=12)\n",
    "plt.ylabel(\"PDF Value\", fontsize=12)\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.axvline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.4)\n",
    "plt.savefig('multi_earth.jpg',dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, this looks worse than what we have using the CDFs with few numbers of people and in practice it frequently is - the CDF is just better. But good to know that there are other options.\n",
    "\n",
    "While the elicitation of probabilities is good in the sense it is bounded and therefore tractable, what about paramters in a geocentric linear model? How can people elicit such things? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate expert responses\n",
    "# Assume three experts provide their mean and confidence intervals for the slope\n",
    "expert_responses = {\n",
    "    \"Expert 1\": {\"mean\": 2.0, \"std\": 0.5},  # Mean and standard deviation\n",
    "    \"Expert 2\": {\"mean\": 2.2, \"std\": 0.3},\n",
    "    \"Expert 3\": {\"mean\": 1.8, \"std\": 0.4},\n",
    "}\n",
    "\n",
    "# Simulate individual distributions\n",
    "n_samples = 1000\n",
    "x = np.linspace(0, 4, n_samples)  # Range for the slope\n",
    "distributions = {\n",
    "    name: sp.stats.norm.pdf(x, loc=data[\"mean\"], scale=data[\"std\"])\n",
    "    for name, data in expert_responses.items()\n",
    "}\n",
    "\n",
    "# Aggregate expert opinions using weighted averaging\n",
    "# Equal weights for simplicity\n",
    "weights = np.array([1/3, 1/3, 1/3])\n",
    "aggregated_pdf = sum(weight * dist for weight, dist in zip(weights, distributions.values()))\n",
    "\n",
    "\n",
    "# Calculate the aggregated mean and standard deviation\n",
    "aggregated_mean = sum(weights[i] * expert_responses[f\"Expert {i+1}\"][\"mean\"] for i in range(len(weights)))\n",
    "aggregated_variance = sum(weights[i] * (expert_responses[f\"Expert {i+1}\"][\"std\"]**2 + \n",
    "                                       (expert_responses[f\"Expert {i+1}\"][\"mean\"] - aggregated_mean)**2) for i in range(len(weights)))\n",
    "aggregated_std = round(np.sqrt(aggregated_variance),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot individual expert distributions and the aggregated distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "for name, pdf in distributions.items():\n",
    "    plt.plot(x, pdf, label=f\"{name} (Mean: {expert_responses[name]['mean']}, Std: {expert_responses[name]['std']})\")\n",
    "plt.plot(x, aggregated_pdf, label=f\"{'Aggregated'} (Mean: {aggregated_mean}, Std: {aggregated_std})\", color=\"black\", lw=2, linestyle=\"--\")\n",
    "\n",
    "# Add plot details\n",
    "plt.title(\"Direct elicitation of Slope in Simple Linear Regression\", fontsize=14)\n",
    "plt.xlabel(\"Slope\", fontsize=12)\n",
    "plt.ylabel(\"Density\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.4)\n",
    "\n",
    "plt.savefig('direct.jpg',dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is fine if we have experts that know something about - and can think in terms of - the mean and standard deviation of a regression slope. But what about normal people? Well first the language has to be good - saying what is the slope isn't good, but saying \"what is the most change you would expect in Y given a change from X1 to X2?\" (with context appropriate words for Y, X1 and X2)...\"and what is the minimum change you would expect?\" And \"How sure are you that the change would be within this range?\"\n",
    "\n",
    "With these statements in hand we can convert into quantitative estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experts provide a plausible range (lower and upper bounds) with a confidence level (e.g., 95%)\n",
    "expert_ranges = {\n",
    "    \"Expert 1\": {\"lower\": 1.5, \"upper\": 2.5, \"confidence\": 0.90},\n",
    "    \"Expert 2\": {\"lower\": 2.0, \"upper\": 2.4, \"confidence\": 0.95},\n",
    "    \"Expert 3\": {\"lower\": 1.6, \"upper\": 2.0, \"confidence\": 0.75},\n",
    "}\n",
    "\n",
    "# Convert ranges to mean and std assuming a normal distribution\n",
    "for name, data in expert_ranges.items():\n",
    "    mean = (data[\"lower\"] + data[\"upper\"]) / 2\n",
    "    std = (data[\"upper\"] - data[\"lower\"]) / (2 * norm.ppf((1 + data[\"confidence\"]) / 2))\n",
    "    expert_ranges[name][\"mean\"] = mean\n",
    "    expert_ranges[name][\"std\"] = std\n",
    "\n",
    "# Calculate the aggregated mean from the weighted means\n",
    "aggregated_mean = sum(\n",
    "    weights[i] * expert_ranges[f\"Expert {i+1}\"][\"mean\"] for i in range(len(weights))\n",
    ")\n",
    "\n",
    "# Calculate the aggregated variance from the weighted variances\n",
    "aggregated_variance = sum(\n",
    "    weights[i] * (expert_ranges[f\"Expert {i+1}\"][\"std\"]**2 +\n",
    "                  (expert_ranges[f\"Expert {i+1}\"][\"mean\"] - aggregated_mean)**2)\n",
    "    for i in range(len(weights))\n",
    ")\n",
    "\n",
    "# Compute the aggregated standard deviation\n",
    "aggregated_std = np.sqrt(aggregated_variance)\n",
    "\n",
    "\n",
    "aggregated_pdf = sp.stats.norm.pdf(x, aggregated_mean, scale=aggregated_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot individual expert distributions and the aggregated distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "for name, pdf in distributions.items():\n",
    "    plt.plot(x, pdf, label=f\"{name} (Mean: {expert_responses[name]['mean']}, Std: {expert_responses[name]['std']})\")\n",
    "plt.plot(x, aggregated_pdf, label=f\"{'Aggregated'} (Mean: {aggregated_mean}, Std: {round(aggregated_std,2)})\", color=\"black\", lw=2, linestyle=\"--\")\n",
    "\n",
    "# Add plot details\n",
    "plt.title(\"Sort-of indirect elicitation of Slope in Simple Linear Regression\", fontsize=14)\n",
    "plt.xlabel(\"Slope\", fontsize=12)\n",
    "plt.ylabel(\"Density\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.4)\n",
    "\n",
    "plt.savefig('indirect.jpg',dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All this is but the tip of the elicitation iceberg - there are many other, very complex ways to derive estimates!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
