{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 11 Lecture 2 - It's instrumental \n",
    "\n",
    "McElreath's lectures for today: https://www.youtube.com/watch?v=oMiSb8GKR0o&list=PLDcUM9US4XdMROZ57-OIRtIK0aOynbgZN&index=19\n",
    "\n",
    "McElreath's lectures for the whole book are available here: https://github.com/rmcelreath/stat_rethinking_2022\n",
    "\n",
    "An R/Stan repo of code is available here: https://vincentarelbundock.github.io/rethinking2/\n",
    "\n",
    "Dustin Stansbury has some lovely PyMC Code available here: https://github.com/dustinstansbury/statistical-rethinking-2023\n",
    "\n",
    "You are encouraged to work through both of these versions to re-enforce what we're doing in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy as sp \n",
    "import random as rd\n",
    "import pdb\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "import dataframe_image as dfi\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "def stdize(x):\n",
    "    return (x-np.mean(x))/np.std(x)\n",
    "\n",
    "def stdizeNA(x):\n",
    "    xnew = x\n",
    "    mask = np.isnan(x)==False\n",
    "    xnew[mask] = (x[mask]-np.mean(x[mask]))/np.std(x[mask])\n",
    "    return xnew\n",
    "\n",
    "def indexall(L):\n",
    "    poo = []\n",
    "    for p in L:\n",
    "        if not p in poo:\n",
    "            poo.append(p)\n",
    "    Ix = np.array([poo.index(p) for p in L])\n",
    "    return poo,Ix\n",
    "\n",
    "def logit(p):\n",
    "    return np.log(p) - np.log(1 - p)\n",
    "\n",
    "def invlogit(p):\n",
    "    return np.exp(p) / (1 + np.exp(p))\n",
    "\n",
    "\n",
    "from matplotlib.patches import Ellipse\n",
    "from scipy.stats import chi2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal instruments\n",
    "\n",
    "Unmeasured variables can ruin your day. It may be that you have the greatest dataset ever, with all the variables you care about collected without error. Except for that one common cause that, for one reason or another, no one bothered to think about. Unfortunately in many cases such unmeasured variables generate an unknowable level of bias that will put all your causal conclusions in doubt. It's just the way of the world.\n",
    "\n",
    "Yet not all is lost - in some cases, if you understand the problem really well, there lies hope. Given some very specific conditions, there may be another measured variable that will save you - the instrument, a variable that bypasses the confounding backdoor and delivers causal inference on a plate.\n",
    "\n",
    "The special conditions are only three, and are often hard to meet, but they can save the day if met. For a simple problem where Education ($E$) affects wages ($W$), we might have some unmeasured confound ($U$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "G = nx.DiGraph(directed=True)\n",
    "G.add_edges_from(\n",
    "    [('U', 'W'), ('U', 'E'), ('E', 'W')], width=3)\n",
    "cdict = {'U':'red', 'W':'black', 'E':'black'}\n",
    "options = {\n",
    "    'node_color': 'white',\n",
    "    'node_size': 400,\n",
    "    'width': 2,\n",
    "    'arrowstyle': '->',\n",
    "    'arrowsize': 15,\n",
    "    \"edgecolors\": [cdict[i] for i in np.array(G.nodes)],\n",
    "    \"alpha\": 0.7\n",
    "}\n",
    "nx.draw_networkx(G, arrows=True, **options)\n",
    "plt.savefig('basicDAG.jpg',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we can find some sort of an instrument, we can overcome this probelm. Here an instrument might be the quarter of the year ($Q$) that someone is born in. This quarter variable $Q$ is instrumenetal if:\n",
    "\n",
    "1. Q is independent of U (Qâ««U)\n",
    "2. Q is not-independent of E (Q$\\not\\!\\perp\\!\\!\\!\\perp$E)\n",
    "3. Q cannot influence W except through E\n",
    "\n",
    "The first condition is obvious - U needs to not confound the instrument Q. The second is also - we need Q to represent the effect of E. The third conditon is because we need the effect of Q to be isolated to working just through E. Importantly there may be cases where this can happen by blocking other backdoor paths (and dagitty has settings for this), but for clarity here it happens because there are no other pathways from Q than through E.\n",
    "\n",
    "For the DAG above, it might look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "G = nx.DiGraph(directed=True)\n",
    "G.add_edges_from(\n",
    "    [('U', 'W'), ('U', 'E'), ('Q', 'E'), ('E', 'W')], width=3)\n",
    "cdict = {'U':'red', 'Q':'green', 'W':'black', 'E':'black'}\n",
    "options = {\n",
    "    'node_color': 'white',\n",
    "    'node_size': 400,\n",
    "    'width': 2,\n",
    "    'arrowstyle': '->',\n",
    "    'arrowsize': 15,\n",
    "    \"edgecolors\": [cdict[i] for i in np.array(G.nodes)],\n",
    "    \"alpha\": 0.7\n",
    "}\n",
    "nx.draw_networkx(G, arrows=True, **options)\n",
    "plt.savefig('InstrumentDAG.jpg',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this all concrete, let's simulate some data for the situation above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of cases\n",
    "N = 500\n",
    "\n",
    "# Create U\n",
    "U_sim = np.random.normal(size=N)\n",
    "# Create Q\n",
    "Q_sim = np.random.choice([1, 2, 3, 4], size=N, replace=True)\n",
    "# Create E\n",
    "E_sim = np.random.normal(loc=U_sim + Q_sim)\n",
    "# Create W\n",
    "W_sim = np.random.normal(loc=U_sim + 0*E_sim)\n",
    "\n",
    "# Standardize the data\n",
    "dat_sim = {\n",
    "    \"W\": sp.stats.zscore(W_sim),\n",
    "    \"E\": sp.stats.zscore(E_sim),\n",
    "    \"Q\": sp.stats.zscore(Q_sim)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here, where the effect of $E$ is set to be zero, let's see what the consequences of U are on our inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as m14_4:\n",
    "    # Priors\n",
    "    aW = pm.Normal(\"aW\", mu=0, sigma=0.2)  # Prior for aW\n",
    "    bEW = pm.Normal(\"bEW\", mu=0, sigma=0.5)  # Prior for bEW\n",
    "    sigma = pm.Exponential(\"sigma\", lam=1)  # Prior for sigma\n",
    "\n",
    "    # Linear model\n",
    "    mu = aW + bEW * dat_sim[\"E\"]\n",
    "\n",
    "    # Likelihood\n",
    "    W = pm.Normal(\"W\", mu=mu, sigma=sigma, observed=dat_sim[\"W\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with m14_4:\n",
    "    # Sampling\n",
    "    trace_basic = pm.sample(chains=4, cores=4, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace_basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_forest(trace_basic, var_names=['aW','bEW','sigma'],figsize=(5,5),combined=True)\n",
    "plt.axvline(0,linestyle=\":\",c='black')\n",
    "plt.tight_layout()\n",
    "plt.savefig('basic.jpg',dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So where we run an ingnorant analysis, where we don't have a DAG to tell us that U is an important confounder, the resutls show that E has a clear effect on W - something around 0.4 [0.3, 0.5]. Clearly we have a problem.\n",
    "\n",
    "Now how should we apply our instrument? Simply add it to the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as m14_5:\n",
    "    # Priors\n",
    "    aW = pm.Normal(\"aW\", mu=0, sigma=0.2)  # Prior for aW\n",
    "    bEW = pm.Normal(\"bEW\", mu=0, sigma=0.5)  # Prior for bEW\n",
    "    bQW = pm.Normal(\"bQW\", mu=0, sigma=0.5)  # Prior for bQW\n",
    "    sigma = pm.Exponential(\"sigma\", lam=1)  # Prior for sigma\n",
    "\n",
    "    # Linear model\n",
    "    mu = aW + bEW * dat_sim[\"E\"] + bQW * dat_sim[\"Q\"]\n",
    "\n",
    "    # Likelihood\n",
    "    W = pm.Normal(\"W\", mu=mu, sigma=sigma, observed=dat_sim[\"W\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with m14_5:\n",
    "    # Sampling\n",
    "    trace_nutty = pm.sample(chains=4, cores=4, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace_nutty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_forest(\n",
    "    [trace_basic,trace_nutty], \n",
    "    model_names = ['Basic','Amplified'],\n",
    "    var_names=['aW','bEW','bQW','sigma'],\n",
    "    figsize=(5,5),\n",
    "    combined=True\n",
    "\n",
    ")\n",
    "plt.axvline(0,linestyle=\":\",c='black')\n",
    "plt.tight_layout()\n",
    "plt.savefig('nutty.jpg',dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now things are going really nuts - the effect of E has become even larger, due to the backdoor path to Q that is negative. Clearly that's not how to introduce the instrument as it simply amplifies the bias of U. \n",
    "\n",
    "Inclusion of Q needs to happen in a different way - through what is known as the *generative model*. A generative model is a way of thinking about modelling whereby you create a model based on how you think the data arose in the first place. In the case where you simulate data it's easy, in that we can simply translate each step in the simulation into a node in the model, so\n",
    "\n",
    "`W_sim = np.random.normal(loc=U_sim + 0*E_sim)`\n",
    "\n",
    "becomes\n",
    "\n",
    "$$\n",
    "W_i \\sim \\text{Normal}(\\mu_{w,i}, \\sigma_w)\n",
    "$$\n",
    "$$\n",
    "\\mu_{w,i} = \\alpha_w + \\beta_{ew} E_i + U_i\n",
    "$$\n",
    "\n",
    "`E_sim = np.random.normal(loc=U_sim + Q_sim)`\n",
    "\n",
    "becomes\n",
    "\n",
    "$$\n",
    "E_i \\sim \\text{Normal}(\\mu_{e,i}, \\sigma_e)\n",
    "$$\n",
    "$$\n",
    "\\mu_{e,i} = \\alpha_e + \\beta_{qe} Q_i + U_i\n",
    "$$\n",
    "\n",
    "`Q_sim = np.random.choice([1, 2, 3, 4], size=N, replace=True)`\n",
    "\n",
    "becomes\n",
    "\n",
    "$$\n",
    "Q_i \\sim \\text{Categorical}([0.25, 0.25, 0.25, 0.25])\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "`U_sim = np.random.normal(size=N)`\n",
    "\n",
    "becomes\n",
    "\n",
    "$$\n",
    "U_i \\sim \\text{Normal}(0, 1)\n",
    "$$\n",
    "\n",
    "With all these elements in place, we can then translate into a full statistical model that averages over $U$ and estimates instead the covariance between $W$ and $E$ - essentially dropping $U$ from both linear models and instead estimating that same effect through the correlation parameter $\\rho$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "W_i \\\\\n",
    "E_i\n",
    "\\end{bmatrix}\n",
    "\\sim \\text{MVNormal}\n",
    "\\left(\n",
    "\\begin{bmatrix}\n",
    "\\mu_{w,i} \\\\\n",
    "\\mu_{e,i}\n",
    "\\end{bmatrix},\n",
    "\\mathbf{S}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mu_{w,i} = \\alpha_w + \\beta_{ew} E_i\n",
    "$$\n",
    "$$\n",
    "\\mu_{e,i} = \\alpha_e + \\beta_{qe} Q_i\n",
    "$$\n",
    "\n",
    "In PyMC this becomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as m14_6:\n",
    "    # Priors for intercepts\n",
    "    aW = pm.Normal(\"aW\", mu=0, sigma=0.2)  # Intercept for W\n",
    "    aE = pm.Normal(\"aE\", mu=0, sigma=0.2)  # Intercept for E\n",
    "\n",
    "    # Priors for slopes\n",
    "    bEW = pm.Normal(\"bEW\", mu=0, sigma=0.5)  # Slope for E in muW\n",
    "    bQE = pm.Normal(\"bQE\", mu=0, sigma=0.5)  # Slope for Q in muE\n",
    "\n",
    "    # Linear models\n",
    "    muW = aW + bEW * dat_sim[\"E\"]\n",
    "    muE = aE + bQE * dat_sim[\"Q\"]\n",
    "\n",
    "    # Priors for correlation matrix and standard deviations\n",
    "    RhoCO = pm.LKJCholeskyCov(\"RhoCO\", n=2, eta=2, sd_dist=pm.Exponential.dist(1))\n",
    "    chol, corr, stds = RhoCO\n",
    "\n",
    "    # Sigma\n",
    "    Sigma = pm.Deterministic('Sigma', stds)\n",
    "\n",
    "    # Rho\n",
    "    Rho = pm.Deterministic('Rho', corr)\n",
    "\n",
    "    # Multivariate normal distribution for (W, E)\n",
    "    cov = pm.Deterministic(\"cov\", chol @ chol.T)\n",
    "    mu = pm.Deterministic(\"mu\", pm.math.stack([muW, muE], axis=1))\n",
    "    observed = np.stack([dat_sim[\"W\"], dat_sim[\"E\"]], axis=1)\n",
    "\n",
    "    # likelihoood\n",
    "    W_E = pm.MvNormal(\"W_E\", mu=mu, chol=chol, observed=observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with m14_6:\n",
    "    # Sampling\n",
    "    trace_boss = pm.sample(chains=4, cores=4, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace_boss, var_names=['aE','aW','bQE','bEW','Rho','Sigma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_forest(\n",
    "    [trace_basic,trace_nutty,trace_boss], \n",
    "    model_names = ['Basic','Amplified','MvN'],\n",
    "    var_names=['aE','aW','bQE','bEW','bQW','sigma','Rho','Sigma'],\n",
    "    figsize=(5,5),\n",
    "    combined=True\n",
    ")\n",
    "plt.axvline(0,linestyle=\":\",c='black')\n",
    "plt.tight_layout()\n",
    "plt.savefig('full.jpg',dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get what we want - $E$ no longer has an effect (we set it to zero after all) and we make the correct inference. What would have happened if we had not had $Q$ in here? The model allows for $U$ after all..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as m14_6_2:\n",
    "    # Priors for intercepts\n",
    "    aW = pm.Normal(\"aW\", mu=0, sigma=0.2)  # Intercept for W\n",
    "    aE = pm.Normal(\"aE\", mu=0, sigma=0.2)  # Intercept for E\n",
    "\n",
    "    # Priors for slopes\n",
    "    bEW = pm.Normal(\"bEW\", mu=0, sigma=0.5)  # Slope for E in muW\n",
    "    bQEx = pm.Normal(\"bQEx\", mu=0, sigma=0.5)  # Slope for Q in muE\n",
    "\n",
    "    # Linear models\n",
    "    muW = aW + bEW * dat_sim[\"E\"]\n",
    "    muE = aE + (bQEx * dat_sim[\"Q\"])*0\n",
    "\n",
    "    # Priors for correlation matrix and standard deviations\n",
    "    RhoCO = pm.LKJCholeskyCov(\"RhoCO\", n=2, eta=2, sd_dist=pm.Exponential.dist(1))\n",
    "    chol, corr, stds = RhoCO\n",
    "\n",
    "    # Sigma\n",
    "    Sigma = pm.Deterministic('Sigma', stds)\n",
    "\n",
    "    # Rho\n",
    "    Rho = pm.Deterministic('Rho', corr)\n",
    "\n",
    "    # Multivariate normal distribution for (W, E)\n",
    "    cov = pm.Deterministic(\"cov\", chol @ chol.T)\n",
    "    mu = pm.Deterministic(\"mu\", pm.math.stack([muW, muE], axis=1))\n",
    "    observed = np.stack([dat_sim[\"W\"], dat_sim[\"E\"]], axis=1)\n",
    "\n",
    "    # likelihoood\n",
    "    W_E = pm.MvNormal(\"W_E\", mu=mu, chol=chol, observed=observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with m14_6_2:\n",
    "    # Sampling\n",
    "    trace_boss2 = pm.sample(chains=4, cores=4, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace_boss2, var_names=['aE','aW','bQEx','bEW','Rho','Sigma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_forest(\n",
    "    [trace_basic,trace_nutty,trace_boss,trace_boss2], \n",
    "    model_names = ['Basic','Amplified','MvN','Ignorant MvN'],\n",
    "    var_names=['aE','aW','bQE','bEW','bQW','sigma','Rho','Sigma'],\n",
    "    figsize=(5,5),\n",
    "    combined=True\n",
    ")\n",
    "plt.axvline(0,linestyle=\":\",c='black')\n",
    "plt.tight_layout()\n",
    "plt.savefig('overfull.jpg',dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the effect blows up - it's better in the sense that it's now overlapping zero, but it also could be anything from the other models. So awful.\n",
    "\n",
    "For hellery let's also run the generative model, where we estimate $U$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model(coords={'group':['W','E']}) as m14_6_x:\n",
    "    # Priors for intercepts\n",
    "    aW = pm.Normal(\"aW\", mu=0, sigma=0.2)  # Intercept for W\n",
    "    aE = pm.Normal(\"aE\", mu=0, sigma=0.2)  # Intercept for E\n",
    "\n",
    "    # Priors for slopes\n",
    "    bEW = pm.Normal(\"bEW\", mu=0, sigma=0.5)  # Slope for E in muW\n",
    "    bQEx = pm.Normal(\"bQEx\", mu=0, sigma=0.5)  # Slope for Q in muE\n",
    "\n",
    "    # Unmeasured\n",
    "    U = pm.Normal('U')\n",
    "\n",
    "    # Linear models\n",
    "    muW = aW + bEW * dat_sim[\"E\"] + U\n",
    "    muE = aE + (bQEx * dat_sim[\"Q\"])*0 + U\n",
    "\n",
    "    # Sigma\n",
    "    Sigma = pm.Exponential('Sigma', 1, dims='group')\n",
    "\n",
    "    # likelihoood\n",
    "    W_ = pm.Normal(\"W_\", muW, Sigma[0], observed=dat_sim[\"W\"])\n",
    "    E_ = pm.Normal(\"E_\", muE, Sigma[1], observed=dat_sim[\"E\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with m14_6_x:\n",
    "    # Sampling\n",
    "    trace_boss3 = pm.sample(chains=4, cores=4, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_forest(\n",
    "    [trace_basic,trace_nutty,trace_boss,trace_boss2,trace_boss3], \n",
    "    model_names = ['Basic','Amplified','MvN','Ignorant MvN','Linear Gen mod.'],\n",
    "    var_names=['aE','aW','bQE','bEW','bQW','sigma','Rho','Sigma'],\n",
    "    figsize=(5,5),\n",
    "    combined=True\n",
    ")\n",
    "plt.axvline(0,linestyle=\":\",c='black')\n",
    "plt.tight_layout()\n",
    "plt.savefig('stuffed.jpg',dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't really work at all - there's not enough information in the independent U to estimate it's effect. \n",
    "\n",
    "\n",
    "Let's try this again where we vary the parameters so that $E$ now has an effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of cases\n",
    "N = 500\n",
    "\n",
    "# Create U\n",
    "U_sim = np.random.normal(size=N)\n",
    "# Create Q\n",
    "Q_sim = np.random.choice([1, 2, 3, 4], size=N, replace=True)\n",
    "# Create E\n",
    "E_sim = np.random.normal(loc=U_sim + Q_sim)\n",
    "# Effect of E\n",
    "bE_sim = -1.\n",
    "# Create W\n",
    "W_sim = np.random.normal(loc=U_sim + bE_sim*E_sim)\n",
    "\n",
    "# Standardize the data\n",
    "dat_sim = {\n",
    "    \"W\": sp.stats.zscore(W_sim),\n",
    "    \"E\": sp.stats.zscore(E_sim),\n",
    "    \"Q\": sp.stats.zscore(Q_sim)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And re-running our model above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as m14_6_2:\n",
    "    # Priors for intercepts\n",
    "    aW = pm.Normal(\"aW\", mu=0, sigma=0.2)  # Intercept for W\n",
    "    aE = pm.Normal(\"aE\", mu=0, sigma=0.2)  # Intercept for E\n",
    "\n",
    "    # Priors for slopes\n",
    "    bEW = pm.Normal(\"bEW\", mu=0, sigma=0.5)  # Slope for E in muW\n",
    "    bQE = pm.Normal(\"bQE\", mu=0, sigma=0.5)  # Slope for Q in muE\n",
    "\n",
    "    # Linear models\n",
    "    muW = aW + bEW * dat_sim[\"E\"]\n",
    "    muE = aE + bQE * dat_sim[\"Q\"]\n",
    "\n",
    "    # Priors for correlation matrix and standard deviations\n",
    "    RhoCO = pm.LKJCholeskyCov(\"RhoCO\", n=2, eta=2, sd_dist=pm.Exponential.dist(1))\n",
    "    chol, corr, stds = RhoCO\n",
    "\n",
    "    # Sigma\n",
    "    Sigma = pm.Deterministic('Sigma', stds)\n",
    "\n",
    "    # Rho\n",
    "    Rho = pm.Deterministic('Rho', corr)\n",
    "\n",
    "    # Multivariate normal distribution for (W, E)\n",
    "    cov = pm.Deterministic(\"cov\", chol @ chol.T)\n",
    "    mu = pm.Deterministic(\"mu\", pm.math.stack([muW, muE], axis=1))\n",
    "    observed = np.stack([dat_sim[\"W\"], dat_sim[\"E\"]], axis=1)\n",
    "\n",
    "    # likelihoood\n",
    "    W_E = pm.MvNormal(\"W_E\", mu=mu, chol=chol, observed=observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with m14_6_2:\n",
    "    # Sampling\n",
    "    trace_bossy = pm.sample(chains=4, cores=4, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace_bossy, var_names=['aE','aW','bQE','bEW','Rho','Sigma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_forest(trace_bossy, var_names=['aE','aW','bQE','bEW','Rho','Sigma'],figsize=(5,5),combined=True)\n",
    "plt.axvline(0,linestyle=\":\",c='black')\n",
    "plt.axvline(bE_sim,c='red',zorder=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('covar.jpg',dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're cooking - we get back the $-1$ish effect of $E$ on $W$. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
